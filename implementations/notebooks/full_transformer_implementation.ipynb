{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667ec589-2108-4bab-8e03-4713217734e6",
   "metadata": {},
   "source": [
    "# Implementation of a full transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b9e20-08c3-4d67-96d0-6e32528a619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "sys.path.append('../modules/')\n",
    "\n",
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a23e67a-24d4-4a93-a8b9-5fa11bb8b52e",
   "metadata": {},
   "source": [
    "Load config file and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99766d49-7d3d-4811-910e-5523ddd223e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'distilbert-base-uncased'\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "\n",
    "# Should we use different tokenizers for the encoder and\n",
    "# the decoder inputs?\n",
    "tokenizer_encoder = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "tokenizer_decoder = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365b880-7700-40a4-a605-e99bff369e4f",
   "metadata": {},
   "source": [
    "Define some example text. We'll work with machine translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d7a88-ec7d-47e0-9acd-1d7faa905811",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = [\n",
    "    \"Six o’clock the siren kicks\",\n",
    "    \"him from a dream\",\n",
    "    \"Tries to shake it off but it just won’t stop\",\n",
    "    \"Can’t find the strength\",\n",
    "    \"but he’s got promises to keep\",\n",
    "    \"And wood to chop before he sleeps\"\n",
    "]\n",
    "\n",
    "text_decoder = [\n",
    "    \"Alle sei del mattino le sirene\",\n",
    "    \"lo cacciano fuori da un sogno\",\n",
    "    \"Provano a scuoterlo ma non si vuole fermare\",\n",
    "    \"Non riesce a trovare la forza\",\n",
    "    \"ma ha delle promesse da mantenere\",\n",
    "    \"E ha della legna da tagliare prima di dormire\"\n",
    "]\n",
    "\n",
    "input_ids_encoder = tokenizer_encoder(\n",
    "    text_encoder,\n",
    "    padding=True,\n",
    "    return_tensors='tf'\n",
    ")['input_ids']\n",
    "\n",
    "input_ids_decoder = tokenizer_decoder(\n",
    "    text_decoder,\n",
    "    padding=True,\n",
    "    return_tensors='tf'\n",
    ")['input_ids']\n",
    "\n",
    "print(input_ids_encoder.shape, input_ids_decoder.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a15b25-25d0-4f50-8ed2-c7bcbb3aa0ff",
   "metadata": {},
   "source": [
    "Test a full (encoder-decoder) transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e0cba-8640-47ba-bdb0-473807be56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trnsf = Transformer(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488ed91-31ad-4e7b-8560-f7645f673136",
   "metadata": {},
   "source": [
    "Forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a9164-a9fa-4ebb-a022-88e045941b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "trnsf([input_ids_encoder, input_ids_decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece8a178-2ef6-4153-833a-28f171f3215b",
   "metadata": {},
   "source": [
    "## Wrap the transformer into a Keras `Model` object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76085661-15e0-4d1e-8025-96a60318ebbf",
   "metadata": {},
   "source": [
    "Build a `Model` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7fe39-8ab3-4b18-b76d-ed20ce188b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder = Input(shape=input_ids_encoder.shape[1:])\n",
    "input_decoder = Input(shape=input_ids_decoder.shape[1:])\n",
    "\n",
    "inputs = [input_encoder, input_decoder]\n",
    "outputs = trnsf(inputs)\n",
    "\n",
    "transformer_model = Model(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f03d10-425a-47f4-a585-9adf5121ffcf",
   "metadata": {},
   "source": [
    "Compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5572f6-cca8-4378-be35-1f1319fb9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    # Loss is chosen randomly: we just want to test\n",
    "    # one training epoch on fake target data.\n",
    "    loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad7244-1f34-4e6b-b2f5-09a39282cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('N parameters:', transformer_model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a61197-d83d-46ef-9482-1a2782639bd4",
   "metadata": {},
   "source": [
    "Generate fake target data and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0e7a4-c4a8-48bb-a69c-ebc8a052314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_targets = tf.ones_like(transformer_model([input_ids_encoder, input_ids_decoder]))\n",
    "\n",
    "transformer_model.fit(\n",
    "    x=[input_ids_encoder, input_ids_decoder],\n",
    "    y=fake_targets,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e111a2-93b1-4f2f-b7b8-4a0f40e42030",
   "metadata": {},
   "source": [
    "Test generating output after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c78c0-ceb5-43d7-86f2-54056135cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model([input_ids_encoder, input_ids_decoder])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
