{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f1349b5-8e04-4cc9-b49f-21b72114a018",
   "metadata": {},
   "source": [
    "# A token classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe5ab62-49ed-4987-94c2-acabb45ddc9e",
   "metadata": {},
   "source": [
    "__Objective:__ build a custom classification token model based on the XLM-R body with a custom classification head.\n",
    "\n",
    "__Source:__ [here](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bcd12-09e3-4171-83e9-64a9c27024f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f472783-291c-443c-be3b-50b93fe5317c",
   "metadata": {},
   "source": [
    "## Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1b3a7-aa4b-4657-b699-620975d235e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(distilbert_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70dbae-80a9-45f0-83c5-50179d23d952",
   "metadata": {},
   "source": [
    "Test the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13b040-3831-43c2-8979-fa9c2a8021bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = [\n",
    "    \"Splinter taught them to be ninja teens (He's a radical rat!)\",\n",
    "    \"Leonardo leads, Donatello does machines (That's a fact, Jack!)\",\n",
    "    \"Raphael is cool but crude (Gimme a break!)\",\n",
    "    \"Michaelangelo is a party dude (Party!)\",\n",
    "    \"Teenage Mutant Ninja Turtles\"\n",
    "]\n",
    "\n",
    "test_tokens = distilbert_tokenizer(\n",
    "    test_text,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "test_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0ddca-234f-47ae-ad24-643a30b0a396",
   "metadata": {},
   "source": [
    "## Build model as a subclass of a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45357dad-c033-4538-9921-ae3e1b5c0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertConfig\n",
    "from transformers.models.distilbert.modeling_tf_distilbert import TFDistilBertModel, TFDistilBertPreTrainedModel\n",
    "from tensorflow.keras.layers import Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8979d-1146-415d-a582-66d157e5a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFDistilBertForTokenClassification(TFDistilBertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        # Load model body.\n",
    "        self.distilbert = TFDistilBertModel(config)\n",
    "\n",
    "        # Initialize token classification head.\n",
    "        self.dropout = Dropout(0.1)\n",
    "        self.classifier = Dense(units=config.num_labels, activation='softmax')\n",
    "\n",
    "    def call(\n",
    "        self,\n",
    "        input_ids,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # Use RoBERTa to get the hiddens states.\n",
    "        outputs = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # Apply classifier.\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff28b20-69cb-4ddb-9e93-f045a299fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classification_model = TFDistilBertForTokenClassification.from_pretrained(distilbert_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60aa47b-6ffe-4b39-a55c-93c4d37a5f8b",
   "metadata": {},
   "source": [
    "Test generating predictions. Output shape: `(batch_shape, seq_len, num_labels)`, where `num_labels` is read from the pretrained model's config object (in case of the `distilbert-base-uncased` checkpoint, there are 2 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a6b6a-1bfb-4cd2-af54-c699e4705128",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids = tf.constant(test_tokens['input_ids'])\n",
    "\n",
    "pred = token_classification_model(input_ids=test_input_ids)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2253316-bf65-4cad-afc9-cf6c356960d2",
   "metadata": {},
   "source": [
    "Check: with softmax activation, summing over the last dimension should give 1 (normalized output probabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81421daa-7d47-48e8-8cab-93f1cce5906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(\n",
    "    pred,\n",
    "    axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8468131-18a0-4f2a-bcb9-84519582d666",
   "metadata": {},
   "source": [
    "## As a pure Tensorflow model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6daad-bc87-40cc-8254-aca7613d0ac4",
   "metadata": {},
   "source": [
    "As an experiment, let's redo the same, this time with less of Huggingface Transformers' machinery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32dd47-c849-44e6-af6f-9dad1a3947b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Input, Model\n",
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a09d9-5605-42fb-871f-d2d43a53cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFDistilBertForTokenClassificationLayer(Layer):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, config, model_ckpt='distilbert-base-uncased'):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Model head (pretrained).\n",
    "        self.distilbert = TFAutoModel.from_pretrained(model_ckpt)\n",
    "\n",
    "        # Model body.\n",
    "        self.dropout = Dropout(config['body_dropout_rate'])\n",
    "        self.classification = Dense(units=config['num_classes'], activation='softmax')\n",
    "\n",
    "    def call(self, input_ids):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        x = self.distilbert(input_ids=input_ids)\n",
    "\n",
    "        x = self.dropout(x[0])\n",
    "        x = self.classification(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5508a-5079-49b6-9520-859174049369",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'body_dropout_rate': 0.1,\n",
    "    'num_classes': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750bf595-5505-41e3-8f48-73da66e37f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classification_layer = TFDistilBertForTokenClassificationLayer(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6504ae1-8b8e-4072-b445-9bcf2d950666",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classification_layer(test_input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103f37dc-ad66-4ec8-bbd7-a9275387cec6",
   "metadata": {},
   "source": [
    "Build a Keras `Model` object and train it on fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ea35c-1a8b-4be0-8334-42cecdae4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=test_input_ids.shape[1:], dtype=tf.int32)\n",
    "outputs = token_classification_layer(inputs)\n",
    "\n",
    "token_classification_model_2 = Model(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf80d70-f3a3-448d-9377-51b0e3f1aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classification_model_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03db58c-634a-4cca-8af8-da90b2f9d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classification_model_2.fit(\n",
    "    x=test_input_ids,\n",
    "    y=tf.random.uniform(shape=token_classification_layer(test_input_ids).shape),\n",
    "    epochs=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
