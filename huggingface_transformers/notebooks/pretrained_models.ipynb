{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ceef3d2-f57f-457a-83ed-afab813a80a6",
   "metadata": {},
   "source": [
    "# Huggingface's pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae858ba-5d10-4146-b140-67f18b91f9ec",
   "metadata": {},
   "source": [
    "Let's experiment with the pretrained models offered by the Huggingface ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b08f5a-98c6-4bec-a9e6-a3ae2c84460e",
   "metadata": {},
   "source": [
    "The `AutoModel` class is the model-level equivalent of what `AutoTokenizer` is for tokenizers: it allows to load a pretrained model (downloading it if it's not present in the local cache) and use it as it is.\n",
    "\n",
    "`AutoModel` is the object that allows to download a model written in its original deep learning framework (PyTorch, TensorFlow or JAX). If a specific framework is needed, models can be converted and loaded with the appropriate object, e.g. `TFAutoModel` for TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcaea3c-4640-4741-a64e-3ce5a189f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, TFAutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944280b-12a9-41c8-bb78-c2360c6f06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This establishes which model to (down)load, and with\n",
    "# which weight values.\n",
    "model_ckpt = 'distilbert-base-uncased'\n",
    "\n",
    "# (Down)load the model.\n",
    "model = TFAutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef23554-d1b9-4b01-b9fa-7fec0e55c13d",
   "metadata": {},
   "source": [
    "## Data and tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a4c2b5-a61f-46ea-8db9-3ef8fb2f15a7",
   "metadata": {},
   "source": [
    "Loaded models assume the input to be already tokenized.\n",
    "\n",
    "__Note:__ models need to be used along with a tokenizer, which must be the one associated to the model (checkpoint) itself, otherwise nothing works! (E.g. different tokenizers in general assume that vocabularies are ordered in different ways)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c80bd0-fb3a-4dbd-b09a-2abe0b7698a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the tokenizer associated to the same model \n",
    "# (same checkpoint).\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f1703-fdb7-4d1c-a125-cafa11a2fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Instead of feeding into their need to “fix” their lives, I try to teach the concept of impermanence, and for those who are interested, I share mindfulness practices to help them understand and internalize the concept. \n",
    "\n",
    "Many of them already have experience with meditation, but it is often a goal-orientated practice in line with fixing themselves. In fact, I find that a goalless practice is the best way to understand impermanence. A goalless practice is about being right here in each moment without any conceptual objective in mind. It means giving up conceptual thinking and concepts, putting the brakes on constantly doing, releasing the need to be in control, and starting to just be in the world as you are. It means sitting with the fact that nothing is permanent, that everything is changing, and that is OK. I think of it as watching the clouds float by on a sunny day. Or, as Soto Zen teacher “Homeless” Kodo Sawaki Roshi said long ago, “Zazen is good for nothing!”\n",
    "\"\"\"\n",
    "\n",
    "documents = [t for t in text.strip().split('\\n') if t != '']\n",
    "\n",
    "print(f'{len(documents)} documents found')\n",
    "\n",
    "for i, document in enumerate(documents):\n",
    "    print(f'\\nDocument {i+1}:')\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11db4d-5e49-46c2-bec7-7a8b0c56c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(documents, padding=True, return_tensors='tf')\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b670d-55c1-4d77-b99e-d878cd7c1cd2",
   "metadata": {},
   "source": [
    "Input TensorFlow tensors. Shape: `(batch_size, n_tokens)` (where `n_tokens` is the number of tokens in the longest sequence as we are using padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4fb361-0044-4e40-b969-f176b619db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f80e17-bb59-4711-887c-aefb8525526e",
   "metadata": {},
   "source": [
    "## Generating an output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9cc52e-c1e5-43ee-a0a0-5a91a12bbdc5",
   "metadata": {},
   "source": [
    "The model expects the output of the tokenizer as its input (so a dict-like object containing both the tokenized sequences as tensors and the attention masks is fine). The output is another dict-like object containing a tensor of shape `(batch_shape, n_tokens, hidden_dim)`, where `hidden_dim` is the output dimension of the model for each token (each token is mapped to a vector of size `hidden_dim`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2de5ef-db02-455f-b563-9a282692bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29250f57-92ea-48d6-bbef-1b9726459b6d",
   "metadata": {},
   "source": [
    "For downstream classification tasks, it's customary to use only the hidden state of the start-of-sentence token as the input feature: this is __NOT__ the same for every sentence and is encoded in a context-dependent way, resulting in a \"summary\" of the sentence itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e96bb-8d16-4d31-8de7-dd936dc88478",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['last_hidden_state'][:, 0, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
