{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e733d8d-16e1-43db-b7b3-8e24ec1a8215",
   "metadata": {},
   "source": [
    "# Experiment with the bag-of-words model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de979113-724e-46f6-ad6c-c58c163ab78b",
   "metadata": {},
   "source": [
    "__Objective:__ classify some documents (movie reviews) using a simple bag-of-words model.\n",
    "\n",
    "Source: https://pyimagesearch.com/2022/07/04/introduction-to-the-bag-of-words-bow-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355e692-8d9c-4d8c-badd-6d505254e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed6bcd2-c761-40b1-a9d1-3d8a120083b3",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f8e0c-d64c-47b6-9a1c-0b5595fe7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data = pd.read_csv('./star_wars_ep_9_reviews_rotten_tomatoes.csv', sep=';', names=['text', 'stars'])\n",
    "\n",
    "reviews_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d933380-6389-485d-a7c5-fd0e6a182944",
   "metadata": {},
   "source": [
    "Quantize the score (stars) to get a classification problem (0: bad, 1: good)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e87cb-06e1-4345-b90f-1f7cc5915a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data['quantized_score'] = reviews_data['stars'].apply(lambda x: 1. if x >= 2.5 else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873474c7-ded8-4b1d-8e08-66317ddce460",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4ab16-0b5a-430e-8c9c-c238143dd652",
   "metadata": {},
   "source": [
    "## Text tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce394c-0ca9-46fe-9a0f-fe78529630af",
   "metadata": {},
   "source": [
    "We use the tokenizer to obtain the word counts for each document. These will be used as our feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab8a3c-4c54-43a7-9743-cb9377d34ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=True)\n",
    "\n",
    "tokenizer.fit_on_texts(reviews_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0d8ba-d55f-4266-920f-454a341887c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = tokenizer.texts_to_matrix(reviews_data['text'], mode='count')\n",
    "\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f92d0-717d-413a-8162-ce6d5152c7f8",
   "metadata": {},
   "source": [
    "## Build and train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94123486-4b45-4e15-a903-680017631206",
   "metadata": {},
   "source": [
    "Build model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d52393-11df-4b22-9c67-fe2fc4198c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inputs to the model.\n",
    "inputs = Input(word_counts.shape[-1])\n",
    "\n",
    "# Define the outputs of the model with Keras'\n",
    "# functional API.\n",
    "x = Dense(units=64, activation='relu')(inputs)\n",
    "x = Dense(units=32, activation='relu')(x)\n",
    "outputs = Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "# Define the Model object.\n",
    "model = Model(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs\n",
    ")\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716e048-0049-4921-b091-999a44fe9a2d",
   "metadata": {},
   "source": [
    "Train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eaa8a1-5ba6-4bf4-b681-d39ff1cc4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(word_counts)\n",
    "y = tf.constant(reviews_data['quantized_score'])\n",
    "\n",
    "model.fit(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    epochs=3,\n",
    "    batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb7ecfe-50ca-4e71-8bf2-ba88d4b8c89a",
   "metadata": {},
   "source": [
    "Test prediction (on training data...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb77941-3e2a-4c1f-97f3-b689bca24b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
